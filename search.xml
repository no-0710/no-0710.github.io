<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HBase 管理工具]]></title>
    <url>%2F2017%2F08%2F24%2Fhbase-web-manager%2F</url>
    <content type="text"><![CDATA[本文档中的 HBase 版本为 hbase-1.2.6，由于版本的问题，其设置或是默认参数可能不一致，或是其他版本，请移步到 官方文档 查看。 Web 管理工具Web 管理工具是 HBase 对外提供的一个 Web 接口，可以通过浏览器进行访问。建议使用 Google Chrome 兼容性会好些。 HMaster 的 Web 接口 端口参数：通过 hbase-site.xml 中的 hbase.master.info.port 进行修改，默认值为16010 通过 http://192.168.7.201:16010 访问 HMaster Web 管理界面包含的状态信息 HBase 的版本信息 HBase 的基本配置信息 HBase在HDFS的存储路径 ZooKeeper的节点信息 集群的负载信息 表、region 和 region server 的信息 可以进行 compat和 split 操作 RegionServer 的Web 接口 端口参数： 通过 hbase-site.xml 中的 hbase.regionserver.info.port 进行修改，默认值为16030 通过 http://192.168.7.201:16030 访问 HBase Shell 管理工具随 HBase 发布的一个命令行的工具，提供针对数据表的 DDL 操作和集群管理。 数据表的 DDL 操作：数据定义语言DDL用来创建数据库中的各种对象—–表、视图、索引、同义词、聚簇等，DDL操作是隐性提交的！不能 Rollback。 在 HBase 的客户端节点，启动 ./hbase shell 。shell 中存在bug，不能使用 backspace 键去删除输入内容，delete键可以使用。 获取帮助信息1hbase(main):010:0&gt; help 获取某个指定的帮助1hbase(main):011:0&gt; help 'create' 创建表12hbase(main):012:0&gt; create 'test','cf'# 以上命令表示创建 'test' 表，其列簇为 'cf' 查看表12hbase(main):013:0&gt; list 'test' # 表名可选hbase(main):014:0&gt; discribe 'test' # 查看表的详细信息 插入数据12hbase(main):015:0&gt; put 'test', 'row1', 'cf:a', 'value-a'# 在 "test" 表，"row1"行，"cf"列簇的 "a"列中 插入值：'value-a' 查看数据12hbase(main):016:0&gt; scan 'test' # 会获得 'test' 表中的所有数据hbase(main):017:0&gt; get 'test', 'row1' # 获得 'test'表中行健为'row1'的数据 disable 和 enable 表在删除或者更改表属性时，需要disable表，更改完成后可以enable表 1234# disable hbase(main):018:0&gt; disable 'test'# enablehbase(main):019:0&gt; enable 'test' 更改表结构1234567# 1. disable tablehbase(main):020:0&gt; disable 'test'# 2. update table struct # 为 test 表更新版本数，并且添加一个新的列簇 "cf1"hbase(main):021:0&gt; alter 'test',&#123;NAME=&gt;'cf',VERSIONS=&gt;'2'&#125;,&#123;NAME=&gt;'cf1'&#125;# 3. enable tablehbase(main):022:0&gt; enable 'test' 删除表12hbase(main):023:0&gt; disable 'test'hbase(main):024:0&gt; drop 'test' flush 操作 HBase 的数据首先会写到 Write Ahead Log（WAL）日志中 然后再写入到 region server 的 memstore 中 在达到一定阈值之后才会写到磁盘中。（阈值大小参数配置 hbase.hregion.memstore.flush.size 默认为128M ） flush操作可以将memstore中的内存数据写到磁盘中 12345# flush 某张表的所有 region 到磁盘hbase(main):025:0&gt; flush 'test'# flush 某张表的特定 region, 需要在 HMaster 的web管理界面中找到 region namehbase(main):026:0&gt; flush 'test,,151542642622.' split 操作split 可以将表的所有 region 或者某个region进行分割。 1hbase(main):027:0&gt; split 'test,,151542642622.' compact 操作把多个小的 HFile 合并成一个大的文件。减少 HFile 的个数，提高读取效率。执行时严重影响HBase性能。 两种 Compact 模式 Minor Compact 把多个小的HFile合成数量较少的大的HFile，合并较快，但是会影响磁盘IO Major Compact 针对一个store下的所有文件合并，删除过期版本数据，删除delete marker数据。可以通过指定时间间隔执行或是手动执行Major compact。这操作很影响性能。 1234# 对表执行 Compact 操作hbase(main):028:0&gt; compact 'test'# 对表执行 Major Compact操作hbase(main):029:0&gt; major_compact 'test' balancer 操作随着数据不断增长，集群数据在不同 region server上分布可能会不均匀，虽然 HBase 会周期性的在后台执行数据平衡操作，但是当我们需要维护或是重启一个 region server 时，会关闭 balancer，这样就使得 region 在 region server 上的分布不均，这时候就需要手工的开启 balancer。 1234# 启动平衡器hbase(main):029:0&gt; balance_switch true# 使用 balancer 命令执行集群的数据平衡hbase(main):030:0&gt; balancer move 操作move 操作可以将一个 region 移动到一个特定的 region server 中。 语法：move ‘ encode region name ‘ , ‘ server name’ ‘encode region name’ : region name 后面的编码 ‘ server name’ 指 在 HMaster Web 界面中看到的 Region Server的列表名称 1hbase(main):031:0&gt; move 'sdasdq12123145124312311', 'slave1,16020,16548441345']]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase manager tools</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HBase 分布式搭建]]></title>
    <url>%2F2017%2F08%2F24%2Fhbase-install%2F</url>
    <content type="text"><![CDATA[准备工作在安装 HBase 前，需要进行以下准备工作 创建三台虚拟主机本文档系统版本为：ubuntu-16.04.2-server-amd64 说明，本文都是使用root用户安装的，你根据自己的情况在其他的用户上操作。 配置互通的静态 IP地址 主机名 IP 角色 ll.das1.com 192.168.7.201 master ll.das2.com 192.168.7.202 slave1 ll.das3.com 192.168.7.203 slave2 修改hosts文件1234567891011root@ll:/opt/tools/hadoop-2.7.3# cat /etc/hosts127.0.0.1 localhost192.168.7.201 ll.das1.com192.168.7.202 ll.das2.com192.168.7.203 ll.das3.com# The following lines are desirable for IPv6 capable hosts::1 localhost ip6-localhost ip6-loopbackff02::1 ip6-allnodesff02::2 ip6-allrouters 软件准备 openssh-server java HBase Version JDK 7 JDK 8 2.0 Not Support yes 1.3 yes yes 1.2 yes yes 1.1 yes can work but is not well tested. zookeeper ZooKeeper 3.4.x is required. HBase makes use of the multi functionality that is only available since Zookeeper 3.4.0. The hbase.zookeeper.useMulti configuration property defaults to true. Refer to HBASE-12241 (The crash of regionServer when taking deadserver’s replication queue breaks replication) and HBASE-6775 (Use ZK.multi when available for HBASE-6710 0.92/0.94 compatibility fix) for background. The property is deprecated and useMulti is always enabled in HBase 2.0. hadoop Hadoop version support matrix “S” = supported “X” = not supported “NT” = Not tested HBase-1.1.x HBase-1.2.x HBase-1.3.x HBase-2.0.x Hadoop-2.0.x-alpha X X X X Hadoop-2.1.0-beta X X X X Hadoop-2.2.0 NT X X X Hadoop-2.3.x NT X X X Hadoop-2.4.x S S S X Hadoop-2.5.x S S S X Hadoop-2.6.0 X X X X Hadoop-2.6.1+ NT S S S Hadoop-2.7.0 X X X X Hadoop-2.7.1+ NT S S S Hadoop-2.8.0 X X X X Hadoop-3.0.0-alphax NT NT NT NT hbase 综上所述：本文档使用以下版本： 名称 版本 jdk jdk-8u111-linux-x64 zookeeper zookeeper-3.4.10 hadoop hadoop-2.7.3 hbase hbase-1.2.6-bin.tar 配置SSH为了允许master node可以无密码的方式登录到其他主机，需要配置用户公钥。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# ll.das1.com 【master】主机上生成公钥root@ll:/# ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:Opz6iZjLT0CkiyWcyKogpukgaCkyScYJzp0ReQpLEZw root@ll.das1.comThe key's randomart image is:+---[RSA 2048]----+|.o=.. ||+E.... ||*+=.o ||B*o.o ||*O.o S ||Xo.. . o ||%o . = ||Bo + o o || .=o+.o |+----[SHA256]-----+root@ll:/# ls ~/.ssh/id_rsa id_rsa.pub known_hosts# 将生成的密钥信息拷贝到三台主机上# root@ll.das1.comroot@ll:~# ssh-copy-id root@ll.das1.com/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"The authenticity of host 'll.das1.com (192.168.7.201)' can't be established.ECDSA key fingerprint is SHA256:3JFgVdBOKZEQWyebavhOfA2AqQ8rVxuh8mf1VGHXJcw.Are you sure you want to continue connecting (yes/no)? yes/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@ll.das1.com's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh 'root@ll.das1.com'"and check to make sure that only the key(s) you wanted were added.# 使用上面同样的方法拷贝到：root@ll.das2.com， root@ll.das3.comroot@ll:~# ssh-copy-id root@ll.das2.comroot@ll:~# ssh-copy-id root@ll.das3.com# 验证：root@ll:~# ssh root@ll.das2.comWelcome to Ubuntu 16.04.2 LTS (GNU/Linux 4.4.0-62-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantageLast login: Wed Aug 23 17:55:00 2017 from 192.168.7.16root@ll:~# hostnamell.das2.com 配置 Java三台虚拟主机都需要安装 jdk 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647root@ll:/opt/tools# cd jdk1.8.0_111/root@ll:/opt/tools/jdk1.8.0_111# pwd/opt/tools/jdk1.8.0_111# 配置环境变量root@ll:/opt/tools/jdk1.8.0_111# vim /etc/profile# /etc/profile: system-wide .profile file for the Bourne shell (sh(1))# and Bourne compatible shells (bash(1), ksh(1), ash(1), ...).if [ "$PS1" ]; then if [ "$BASH" ] &amp;&amp; [ "$BASH" != "/bin/sh" ]; then # The file bash.bashrc already sets the default PS1. # PS1='\h:\w\$ ' if [ -f /etc/bash.bashrc ]; then . /etc/bash.bashrc fi else if [ "`id -u`" -eq 0 ]; then PS1='# ' else PS1='$ ' fi fifiif [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset ifi# javaexport JAVA_HOME=/opt/tools/jdk1.8.0_111export PATH=$PATH:$JAVA_HOME/bin# 使环境变量生效root@ll:/opt/tools/jdk1.8.0_111# source /etc/profile# 验证root@ll:/opt# java -versionjava version "1.8.0_111"Java(TM) SE Runtime Environment (build 1.8.0_111-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.111-b14, mixed mode)root@ll:/opt# 安装 Hadoop123456789101112131415161718192021222324252627282930313233343536373839# 解压安装 Hadooproot@ll:/opt/software# tar -zxf hadoop-2.7.3.tar.gz -C /opt/tools/root@ll:/opt/software# cd /opt/tools/hadoop-2.7.3/# 修改配置文件root@ll:/opt/tools/hadoop-2.7.3# cd etc/hadoop/root@ll:/opt/tools/hadoop-2.7.3/etc/hadoop# lltotal 160drwxr-xr-x 2 root root 4096 Aug 17 2016 ./drwxr-xr-x 3 root root 4096 Aug 17 2016 ../-rw-r--r-- 1 root root 4436 Aug 17 2016 capacity-scheduler.xml-rw-r--r-- 1 root root 1335 Aug 17 2016 configuration.xsl-rw-r--r-- 1 root root 318 Aug 17 2016 container-executor.cfg-rw-r--r-- 1 root root 774 Aug 17 2016 core-site.xml-rw-r--r-- 1 root root 3589 Aug 17 2016 hadoop-env.cmd-rw-r--r-- 1 root root 4224 Aug 17 2016 hadoop-env.sh-rw-r--r-- 1 root root 2598 Aug 17 2016 hadoop-metrics2.properties-rw-r--r-- 1 root root 2490 Aug 17 2016 hadoop-metrics.properties-rw-r--r-- 1 root root 9683 Aug 17 2016 hadoop-policy.xml-rw-r--r-- 1 root root 775 Aug 17 2016 hdfs-site.xml-rw-r--r-- 1 root root 1449 Aug 17 2016 httpfs-env.sh-rw-r--r-- 1 root root 1657 Aug 17 2016 httpfs-log4j.properties-rw-r--r-- 1 root root 21 Aug 17 2016 httpfs-signature.secret-rw-r--r-- 1 root root 620 Aug 17 2016 httpfs-site.xml-rw-r--r-- 1 root root 3518 Aug 17 2016 kms-acls.xml-rw-r--r-- 1 root root 1527 Aug 17 2016 kms-env.sh-rw-r--r-- 1 root root 1631 Aug 17 2016 kms-log4j.properties-rw-r--r-- 1 root root 5511 Aug 17 2016 kms-site.xml-rw-r--r-- 1 root root 11237 Aug 17 2016 log4j.properties-rw-r--r-- 1 root root 931 Aug 17 2016 mapred-env.cmd-rw-r--r-- 1 root root 1383 Aug 17 2016 mapred-env.sh-rw-r--r-- 1 root root 4113 Aug 17 2016 mapred-queues.xml.template-rw-r--r-- 1 root root 758 Aug 17 2016 mapred-site.xml.template-rw-r--r-- 1 root root 10 Aug 17 2016 slaves-rw-r--r-- 1 root root 2316 Aug 17 2016 ssl-client.xml.example-rw-r--r-- 1 root root 2268 Aug 17 2016 ssl-server.xml.example-rw-r--r-- 1 root root 2191 Aug 17 2016 yarn-env.cmd-rw-r--r-- 1 root root 4567 Aug 17 2016 yarn-env.sh-rw-r--r-- 1 root root 690 Aug 17 2016 yarn-site.xml 修改 hadoop-env.sh12345678root@ll:/opt/tools/hadoop-2.7.3/etc/hadoop# echo $JAVA_HOME/opt/tools/jdk1.8.0_111root@ll:/opt/tools/hadoop-2.7.3/etc/hadoop# vim hadoop-env.sh # Licensed to the Apache Software Foundation (ASF) under one# ...# The java implementation to use.export JAVA_HOME=/opt/tools/jdk1.8.0_111# ... 修改 core-site.xml 文件12345678910111213141516171819202122232425262728&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://ll.das1.com:8020&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/tools/hadoop-2.7.3/store/tmp&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 修改 hdfs-site.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!-- Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file.--&gt;&lt;!-- Put site-specific property overrides in this file. --&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address&lt;/name&gt; &lt;value&gt;ll.das1.com:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;ll.das3.com:50090&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/opt/tools/hadoop-2.7.3/store/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;/opt/tools/hadoop-2.7.3/store/data&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 slave 文件12ll.das2.com ll.das3.com 将Hadoop安装文件分发到其他主机上12root@ll:/opt/tools# scp -r hadoop-2.7.3/ root@ll.das2.com:/opt/tools/root@ll:/opt/tools# scp -r hadoop-2.7.3/ root@ll.das3.com:/opt/tools/ 执行命令 ( namenode 节点执行)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869root@ll:/opt/tools# cd hadoop-2.7.3/bin/root@ll:/opt/tools/hadoop-2.7.3/bin# lltotal 328drwxr-xr-x 2 root root 4096 Aug 17 2016 ./drwxr-xr-x 10 root root 4096 Aug 23 23:11 ../-rwxr-xr-x 1 root root 108813 Aug 17 2016 container-executor*-rwxr-xr-x 1 root root 6488 Aug 17 2016 hadoop*-rwxr-xr-x 1 root root 8514 Aug 17 2016 hadoop.cmd*-rwxr-xr-x 1 root root 12223 Aug 17 2016 hdfs*-rwxr-xr-x 1 root root 7238 Aug 17 2016 hdfs.cmd*-rwxr-xr-x 1 root root 5953 Aug 17 2016 mapred*-rwxr-xr-x 1 root root 6094 Aug 17 2016 mapred.cmd*-rwxr-xr-x 1 root root 1776 Aug 17 2016 rcc*-rwxr-xr-x 1 root root 125269 Aug 17 2016 test-container-executor*-rwxr-xr-x 1 root root 13352 Aug 17 2016 yarn*-rwxr-xr-x 1 root root 11054 Aug 17 2016 yarn.cmd*root@ll:/opt/tools/hadoop-2.7.3/bin# ./hdfs namenode -format17/08/23 23:35:24 INFO common.Storage: Storage directory /opt/tools/hadoop-2.7.3/store/name has been successfully formatted.# 输出中出现以上日志，就说明已经格式化成功。root@ll:/opt/tools/hadoop-2.7.3/bin# cd ../sbinroot@ll:/opt/tools/hadoop-2.7.3/sbin# lltotal 128drwxr-xr-x 2 root root 4096 Aug 17 2016 ./drwxr-xr-x 10 root root 4096 Aug 23 23:11 ../-rwxr-xr-x 1 root root 2752 Aug 17 2016 distribute-exclude.sh*-rwxr-xr-x 1 root root 6452 Aug 17 2016 hadoop-daemon.sh*-rwxr-xr-x 1 root root 1360 Aug 17 2016 hadoop-daemons.sh*-rwxr-xr-x 1 root root 1597 Aug 17 2016 hdfs-config.cmd*-rwxr-xr-x 1 root root 1427 Aug 17 2016 hdfs-config.sh*-rwxr-xr-x 1 root root 2291 Aug 17 2016 httpfs.sh*-rwxr-xr-x 1 root root 3128 Aug 17 2016 kms.sh*-rwxr-xr-x 1 root root 4080 Aug 17 2016 mr-jobhistory-daemon.sh*-rwxr-xr-x 1 root root 1648 Aug 17 2016 refresh-namenodes.sh*-rwxr-xr-x 1 root root 2145 Aug 17 2016 slaves.sh*-rwxr-xr-x 1 root root 1727 Aug 17 2016 start-all.cmd*-rwxr-xr-x 1 root root 1471 Aug 17 2016 start-all.sh*-rwxr-xr-x 1 root root 1128 Aug 17 2016 start-balancer.sh*-rwxr-xr-x 1 root root 1360 Aug 17 2016 start-dfs.cmd*-rwxr-xr-x 1 root root 3734 Aug 17 2016 start-dfs.sh*-rwxr-xr-x 1 root root 1357 Aug 17 2016 start-secure-dns.sh*-rwxr-xr-x 1 root root 1524 Aug 17 2016 start-yarn.cmd*-rwxr-xr-x 1 root root 1347 Aug 17 2016 start-yarn.sh*-rwxr-xr-x 1 root root 1718 Aug 17 2016 stop-all.cmd*-rwxr-xr-x 1 root root 1462 Aug 17 2016 stop-all.sh*-rwxr-xr-x 1 root root 1179 Aug 17 2016 stop-balancer.sh*-rwxr-xr-x 1 root root 1414 Aug 17 2016 stop-dfs.cmd*-rwxr-xr-x 1 root root 3206 Aug 17 2016 stop-dfs.sh*-rwxr-xr-x 1 root root 1340 Aug 17 2016 stop-secure-dns.sh*-rwxr-xr-x 1 root root 1595 Aug 17 2016 stop-yarn.cmd*-rwxr-xr-x 1 root root 1340 Aug 17 2016 stop-yarn.sh*-rwxr-xr-x 1 root root 4295 Aug 17 2016 yarn-daemon.sh*-rwxr-xr-x 1 root root 1353 Aug 17 2016 yarn-daemons.sh*# 启动 hdfs root@ll:/opt/tools/hadoop-2.7.3/sbin# ./start-dfs.sh Starting namenodes on [ll.das1.com]ll.das1.com: starting namenode, logging to /opt/tools/hadoop-2.7.3/logs/hadoop-root-namenode-ll.das1.com.outll.das2.com: starting datanode, logging to /opt/tools/hadoop-2.7.3/logs/hadoop-root-datanode-ll.das2.com.outll.das3.com: starting datanode, logging to /opt/tools/hadoop-2.7.3/logs/hadoop-root-datanode-ll.das3.com.outStarting secondary namenodes [ll.das3.com]ll.das3.com: starting secondarynamenode, logging to /opt/tools/hadoop-2.7.3/logs/hadoop-root-secondarynamenode-ll.das3.com.outroot@ll:/opt/tools/hadoop-2.7.3/sbin# jps3889 Jps3661 NameNode# 关闭 hdfs root@ll:/opt/tools/hadoop-2.7.3/sbin# ./stop-dfs.sh 使用浏览器访问：http://192.168.7.201:50070/ 有意外惊喜哦！ 安装 ZooKeeper 在主节点安装ZooKeeper 将conf目录下的zoo_sample.cfg修改为zoo.cfg 修改zoo.cfg 1234567891011121314151617181920212223242526272829303132333435# 修改 zoo.cfg # The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/opt/tools/zookeeper-3.4.10/zkdatadataLogDir=/opt/tools/zookeeper-3.4.10/zklogs# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to "0" to disable auto purge feature#autopurge.purgeInterval=1server.1=ll.das1.com:2888:3888server.2=ll.das2.com:2888:3888server.3=ll.das3.com:2888:3888 根据server 的编号在不同的主机的 /opt/tools/zookeeper-3.4.10/zkdata 中创建 myid ，并写入编号。 12345678910111213141516# 启动 ZooKeeperroot@ll:/opt/tools/zookeeper-3.4.10/bin# ./zkServer.sh startZooKeeper JMX enabled by defaultUsing config: /opt/tools/zookeeper-3.4.10/bin/../conf/zoo.cfgStarting zookeeper ... STARTEDroot@ll:/opt/tools/zookeeper-3.4.10/bin# jps3953 Jps3928 QuorumPeerMain3661 NameNode# 查看状态root@ll:/opt/tools/zookeeper-3.4.10/bin# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/tools/zookeeper-3.4.10/bin/../conf/zoo.cfgMode: follower# 停止 ZooKeeperroot@ll:/opt/tools/zookeeper-3.4.10/bin# ./zkServer.sh stop 安装 HBase 的集群 确保 HDFS 处于启动状态 在主节点解压缩 HBase 修改 HBase 的环境变量配置文件：hbase-env.sh export JAVA_HOME=/opt/tools/jdk1.8.0_111 修改 hbase-site.xml 文件 修改 regionservers 文件 同步从节点 解压缩 HBase文件12345678910# root@ll:/opt/software# lltotal 522716drwxr-xr-x 2 root root 4096 Aug 19 01:58 ./drwxr-xr-x 4 root root 4096 Aug 19 01:56 ../-rw-r--r-- 1 root root 214092195 Jan 4 2017 hadoop-2.7.3.tar.gz-rw-r--r-- 1 root root 104659474 Jul 24 02:48 hbase-1.2.6-bin.tar.gz-rw-r--r-- 1 root root 181442359 Jan 5 2017 jdk-8u111-linux-x64.tar.gz-rw-r--r-- 1 root root 35042811 Jul 24 02:48 zookeeper-3.4.10.tar.gzroot@ll:/opt/software# tar -zxf hbase-1.2.6-bin.tar.gz -C /opt/tools/ 修改 hbase-env.sh 文件12345678910111213141516root@ll:/opt/tools/hbase-1.2.6/conf# lltotal 48drwxr-xr-x 2 root root 4096 Aug 24 00:26 ./drwxr-xr-x 7 root root 4096 Aug 24 00:24 ../-rw-r--r-- 1 root root 1811 Dec 26 2015 hadoop-metrics2-hbase.properties-rw-r--r-- 1 root root 4537 Jan 28 2016 hbase-env.cmd-rw-r--r-- 1 root root 7468 Jan 28 2016 hbase-env.sh-rw-r--r-- 1 root root 2257 Dec 26 2015 hbase-policy.xml-rw-r--r-- 1 root root 934 Dec 26 2015 hbase-site.xml-rw-r--r-- 1 root root 4603 May 28 23:29 log4j.properties-rw-r--r-- 1 root root 10 Dec 26 2015 regionserversroot@ll:/opt/tools/hbase-1.2.6/conf# vim hbase-env.sh #...# The java implementation to use. Java 1.7+ required.export JAVA_HOME=/opt/tools/jdk1.8.0_111# ... 修改 hbase-site.xml 文件1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0"?&gt;&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;&lt;!--/** * * Licensed to the Apache Software Foundation (ASF) under one * or more contributor license agreements. See the NOTICE file * distributed with this work for additional information * regarding copyright ownership. The ASF licenses this file * to you under the Apache License, Version 2.0 (the * "License"); you may not use this file except in compliance * with the License. You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an "AS IS" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */--&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://ll.das1.com:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;ll.das1.com,ll.das2.com,ll.das3.com&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/opt/tools/zookeeper-3.4.10/zkdata&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; &lt;value&gt;2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改 regionservers 文件12ll.das2.comll.das3.com 同步从节点并启动123456789101112# 同步root@ll:/opt/tools# scp -r hbase-1.2.6/ root@ll.das2.com:/opt/tools/root@ll:/opt/tools# scp -r hbase-1.2.6/ root@ll.das3.com:/opt/tools/# 启动root@ll:/opt/tools# cd hbase-1.2.6/bin/root@ll:/opt/tools/hbase-1.2.6/bin# ./start-hbase.sh root@ll:/opt/tools/hbase-1.2.6/bin# jps3928 QuorumPeerMain4360 HMaster3661 NameNode4542 Jps# 关闭 测试1234567891011121314151617181920212223242526272829303132333435root@ll:/opt/tools/hbase-1.2.6/bin# ./hbase shell2017-08-24 01:04:24,597 WARN [main] util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableHBase Shell; enter 'help&lt;RETURN&gt;' for list of supported commands.Type "exit&lt;RETURN&gt;" to leave the HBase ShellVersion 1.2.6, rUnknown, Mon May 29 02:25:32 CDT 2017hbase(main):001:0&gt;# 创建 表 "test" 并指定其列簇为 "cf1"hbase(main):002:0* create 'test', 'cf1'0 row(s) in 1.8090 seconds=&gt; Hbase::Table - test# 查看所有的表hbase(main):003:0&gt; listTABLEtest 1 row(s) in 0.0500 seconds=&gt; ["test"]# 向 "test" 表中添加数据hbase(main):004:0&gt; put 'test', 'row1', 'cf1:a','value1' 0 row(s) in 0.3160 secondshbase(main):005:0&gt; put 'test', 'row1', 'cf1:b','value2' 0 row(s) in 0.0160 seconds# 全表扫描hbase(main):006:0&gt; scan 'test'ROW COLUMN+CELL row1 column=cf1:a, timestamp=1503562049190, value=value1 row1 column=cf1:b, timestamp=1503562070298, value=value21 row(s) in 0.0810 seconds# disable 表 testhbase(main):007:0&gt; disable 'test'0 row(s) in 2.3240 seconds# 删除 "test" 表hbase(main):008:0&gt; drop 'test'0 row(s) in 1.2760 seconds 浏览器访问：http://192.168.7.201:16010/master-status 即可看到 HBase web 管理界面]]></content>
      <categories>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>HBase</tag>
        <tag>ZooKeeper</tag>
        <tag>HDFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB 单节点搭建]]></title>
    <url>%2F2017%2F08%2F20%2Fmongodb-creat%2F</url>
    <content type="text"><![CDATA[1. 单机 MongoDB 安装MongoDB 提供了 linux 各发行版本 64 位的安装包，你可以在官网下载安装包。下载地址：https://www.mongodb.com/download-center?ct=false#community下载完安装包，并解压 tgz（以下演示的是 64 位 ubuntu 上的安装） 12345# 解压 mongoDB 压缩包root@das:/home/software# tar -zxvf mongodb-linux-x86_64-ubuntu1604-3.4.6.tgz -C /home/tools/root@das:/home/software# mv /home/tools/mongodb-linux-x86_64-ubuntu1604-3.4.6/ /home/tools/mongodb-3.4.6# 进入 mongodb 文件夹root@das:/home/software# cd /home/tools/mongodb-3.4.6/ 配置环境变量 /etc/profile 123456# /etc/profile 追加内容 export MONGODB_HOME=/home/tools/mongodb-3.4.6export PATH=$PATH:$MONGODB_HOME/bin# 保存，生效环境source /etc/profile 2. 创建数据库目录12345678910111213141516171819# 创建目录root@das:/home/tools/mongodb-3.4.6# mkdir db logs# 创建配置文件root@das:/home/tools/mongodb-3.4.6/bin# vim mongodb.conf# db pathdbpath = /home/tools/mongodb-3.4.6/db# 日志文件存放的位置logpath = /home/tools/mongodb-3.4.6/logs/mongodb.log# 端口port = 27017# 以守护程序的方式启动，即后台运行fork = true# 日志输出的方式logappend = true# 设置每个数据库将被保存在一个单独的目录中# directoryerdb = true# 开启认证auth = false 3. 启动 mongodb1234root@das:/home/tools/mongodb-3.4.6/bin# ./mongod -f mongodb.conf about to fork child process, waiting until server is ready for connections.forked process: 1011child process started successfully, parent exiting 4. 关闭 mongodb12root@das:/home/tools/mongodb-3.4.6/bin# ./mongod -f mongodb.conf --shutdownkilling process with pid: 1011 5. MongoDB 权限5.1 权限介绍MongoDB安装完成后，默认是不需要输入用户名密码即可登录的，但是往往数据库方面我们会出于安全性的考虑而设置用户名密码，本篇文章主要介绍了MongoDB添加管理员/普通用户的方法。 在我们使用的关系型数据库中，一般都是含有权限控制的，也就是说配置什么用户访问什么数据库，什么数据表，什么用户可以对表进行增删改，什么用户可以对表进行读取等等都是可以配置，那么MongoDB作为一个非关系型数据库的典型，它其实也是可以配置的，而掌握MongoDB的权限我们只需要简单理解下面几点，后面按照下面的几点去配置即可。 MongoDB是没有默认管理员账号的，所以要先添加管理员账号，在开启权限认证。 切换到admin数据库，添加的账号才是管理员的账号。 用户只能在用户所在的数据库登录，包括管理员账号。 管理员可以管理所有的数据库，但是不能直接管理其它数据库，要先在admin数据库中认证才可以，也是为了 安全性考虑。 5.2 权限设置创建一个root用户，并赋予超级管理员权限（root），超级管理员可以管理MongoDB下的所有库以及权限、备份及集群等操作。 123456789root@das:/home/tools/mongodb-3.4.6/bin# ./mongoMongoDB shell version v3.4.6connecting to: mongodb://127.0.0.1:27017MongoDB server version: 3.4.6Welcome to the MongoDB shell.&gt; use adminswitched to db admin&gt; db.createUser(&#123;user:"root",pwd:"123qwe",roles:["root"]&#125;)Successfully added user: &#123; "user" : "root", "roles" : [ "root" ] &#125; 为admin库创建一个admin用户，并赋予管理员权限。 123456789101112&gt; use adminswitched to db admin&gt; db.createUser(&#123;user:"admin",pwd:"admin",roles:[&#123;role:"userAdminAnyDatabase",db:"admin"&#125;]&#125;)Successfully added user: &#123; "user" : "admin", "roles" : [ &#123; "role" : "userAdminAnyDatabase", "db" : "admin" &#125; ]&#125; 新建一个数据库库smaster，给该库添加一个用户sm，密码sm123qwe，并赋予读写及管理员权限。 1234&gt; use smasterswitched to db smaster&gt; db.createUser(&#123;user:"sm",pwd:"sm123qwe",roles:["readWrite","dbAdmin"]&#125;)Successfully added user: &#123; "user" : "sm", "roles" : [ "readWrite", "dbAdmin" ] &#125; 认证创建的用户，此步骤非常重要。认证完成之后，退出shell 1234&gt; db.auth("sm","sm123qwe")1 # 1 - 表示认证成功，0 - 表示失败exitbye 开启验证，重启MongoDB服务。修改配置文件mongodb.conf，添加以下内容auth=true，然后保存。 Python api – pymongo 验证操作集合1234567# 创建链接mongodb_client = MongoClient(host="192.168.7.51", port=27017)mongodb_db = self.mongodb_client["smaster"]# 权限验证if not mongodb_db.authenticate(name="sm", password="sm123qwe"): raise ConnectionError("can't connect to mongodb, please check configure.")mongodb_collection = mongodb_db["proj_infos"]]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>mongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyInstaller 打包 Python 程序]]></title>
    <url>%2F2017%2F08%2F20%2FpyInstaller%2F</url>
    <content type="text"><![CDATA[1. Code structure123456789101112131415NodeSlave---|[D] conf # configure folder |--- slave.ini # configure file |---|[D] resource # resource folder |--- node.ico # icon file [ 128*128 ] |---|[D] slave # python package---|[D] build # pyInstaller generate build folder automatically---|[D] dist # pyInstaller generate dist folder automatically |---[D] slave_client # pyInstaller generate program folder |---| slave_client.py # program entrance: main()---| slave_client.spec # pyInstaller spec temporary file---| readme.md # read me file 2. Build executable files 使用 virtualenv 构建纯净的 Python开发环境。 123456# 安装 virtualenv$ pip install virtualenv# 创建一个虚拟环境$ cd D:\Coder\PythonVirtualEnv# 克隆一份Python环境至 D:\Coder\PythonVirtualEnv\venv$ virtualenv venv 在虚拟环境中，使用 pip install xxxx 安装项目依赖。 1234# cmd 执行批处理文件进入虚拟环境 venv$ cd D:\Coder\PythonVirtualEnv$ venv\Scripts\activate.bat(venv) $ pip install kazoo ... 使用 pyInstaller 打包程序。 123456# 在虚拟环境 venv 中执行打包操作(venv) $ cd E:\Coder\SMasterManager\NodeSlave# 执行打包操作(venv) $ pyinstaller --add-data="conf/slave.ini;conf" ^ --icon=resource/node.ico ^ slave_client.py]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>PyInstaller</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云服务器 ECS Linux SWAP 配置概要说明]]></title>
    <url>%2F2017%2F08%2F20%2Flinux-swap-settings%2F</url>
    <content type="text"><![CDATA[SWAP 简介Linux 中的 SWAP（交换分区），类似于 Windows 的虚拟内存。系统会把一部分硬盘空间虚拟成内存使用，将系统内非活动内存换页到 SWAP，以提高系统可用内存。 开启 SWAP1、创建用于交换分区的文件： 1dd if=/dev/zero of=/mnt/swap bs=block_size count=number_of_block 注：block_size、number_of_block 大小可以自定义，比如 bs=1M count=1024 代表设置 1G 大小 SWAP 分区。交换空间一般是物理内存的2倍或4倍 2、设置交换分区文件： 1mkswap /mnt/swap 3、立即启用交换分区文件 1swapon /mnt/swap 注：如果在 /etc/rc.local 中有 swapoff -a 需要修改为 swapon -a 4、设置开机时自启用 SWAP 分区： 需要修改文件 /etc/fstab 中的 SWAP 行，添加 1/mnt/swap swap swap defaults 0 0 注：/mnt/swap 路径可以修改，可以根据创建的 SWAP 文件具体路径来配置。 5、修改 swpapiness 参数 在 Linux 系统中，可以通过查看 /proc/sys/vm/swappiness 内容的值来确定系统对 SWAP 分区的使用原则。当 swappiness 内容的值为 0 时，表示最大限度地使用物理内存，物理内存使用完毕后，才会使用 SWAP 分区。当 swappiness 内容的值为 100 时，表示积极地使用 SWAP 分区，并且把内存中的数据及时地置换到 SWAP 分区。 查看修改前为 0，需要在物理内存使用完毕后才会使用 SWAP 分区： 可以使用下述方法临时修改此参数，假设我们配置为空闲内存少于 10% 时才使用 SWAP 分区： 1echo 10 &gt;/proc/sys/vm/swappiness 若需要永久修改此配置，在系统重启之后也生效的话，可以修改 /etc/sysctl.conf 文件，并增加以下内容： 1# vim /etc/sysctl.confvm.swappiness=10# sysctl -p 关闭 SWAP当系统出现内存不足时，开启 SWAP 可能会因频繁换页操作，导致 IO 性能下降。如果要关闭 SWAP，可以采用如下方法。 1、free -m 查询 SWAP 分区设置： 2、使用命令 swapoff 关闭 SWAP，比如： 1swapoff /mnt/swap 3、修改 /etc/fstab 文件，删除或注释相关配置，取消 SWAP 的自动挂载： 4、 通过 free -m 确认 SWAP 已经关闭。 5、 swappiness 参数调整： 可以使用下述方法临时修改此参数，这里配置为 0%： 1echo 0 &gt;/proc/sys/vm/swappiness 若需要永久修改此配置，在系统重启之后也生效的话，可以修改 /etc/sysctl.conf 文件，并增加以下内容： 1# vim /etc/sysctl.confvm.swappiness=0# sysctl -p]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>Ubuntu SWAP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建 GitLab 服务器 ( Ubuntu 16.04 )]]></title>
    <url>%2F2017%2F08%2F20%2Fbuild-gitlab%2F</url>
    <content type="text"><![CDATA[1. Install and configure the necessary dependenciesIf you install Postfix to send email please select ‘Internet Site’ during setup. Instead of using Postfix you can also use Sendmail or configure a custom SMTP server and configure it as an SMTP server. On CentOS, the commands below will also open HTTP and SSH access in the system firewall. 1sudo apt-get install curl openssh-server ca-certificates postfix -y 2. Add the GitLab package server and install the package12curl -sS https://packages.gitlab.com/install/repositories/gitlab/gitlab-ce/script.deb.sh | sudo bashsudo apt-get install gitlab-ce 3. Configure and start GitLab1sudo gitlab-ctl reconfigure 4. Browse to the hostname and loginOn your first visit, you’ll be redirected to a password reset screen to provide the password for the initial administrator account. Enter your desired password and you’ll be redirected back to the login screen. The default account’s username is root. Provide the password you created earlier and login. After login you can change the username if you wish. 5. Gitlab congfigureAdd the following configuration information to /etc/gitlab/gitlab.rb and run gitlab-ctl reconfigure. 5.1. Configuring the external URL for GitLabIn order for GitLab to display correct repository clone links to your users it needs to know the URL under which it is reached by your users, e.g. http://gitlab.example.com. Add or edit the following line in /etc/gitlab/gitlab.rb: 1external_url "http://xxxx.xx.xxx.xxx" 或者 123external_url "http://xxx.gitlab.com"# 需要设置 hosts# xxxx.xx.xxx.xxx xxx.gitlab.com Run sudo gitlab-ctl reconfigure for the change to take effect. 5.2. Email configure about SMTP当我们需要使用密码找回等邮件提醒服务。需要配置gitlab的配置文件 12345678910111213141516171819# vim /etc/gitlab/gitlab.rbgitlab_rails['time_zone'] = 'Asia/Shanghai'### Email Settingsgitlab_rails['gitlab_email_enabled'] = truegitlab_rails['gitlab_email_from'] = 'xxxxxx@outlook.com'gitlab_rails['gitlab_email_display_name'] = 'xxxooo'### GitLab email server settings# outlook emailgitlab_rails['smtp_enable'] = truegitlab_rails['smtp_address'] = "smtp-mail.outlook.com"gitlab_rails['smtp_port'] = 587gitlab_rails['smtp_user_name'] = "xxxxxx@outlook.com"gitlab_rails['smtp_password'] = "your password"gitlab_rails['smtp_domain'] = "smtp-mail.outlook.com"gitlab_rails['smtp_authentication'] = "login"gitlab_rails['smtp_enable_starttls_auto'] = truegitlab_rails['smtp_openssl_verify_mode'] = 'peer'user['git_user_email'] = "xxxxxx@outlook.com" 5.3. 设置 HTTPS后续补充]]></content>
      <categories>
        <category>Code</category>
      </categories>
      <tags>
        <tag>GitLab</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
</search>
